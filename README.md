In this project, I implemented a Cultural Consensus Theory model in PyMC to estimate both the shared answers to plant knowledge questions and each informant’s individual competence. I modeled each informant's competence $D_i$ using a Uniform(0.5, 1.0) prior, assuming they perform at least at chance but can approach expert-level accuracy. For the latent consensus answers $Z_j$, I used a Bernoulli(0.5) prior to stay neutral in the absence of prior cultural knowledge. The model defines the probability of a response as $p_{ij} = Z_j \cdot D_i + (1 - Z_j)(1 - D_i)$, meaning informants are more likely to agree with the consensus if they are more competent. I used PyMC’s MCMC sampler with 500 draws and 2 chains (plus tuning), and all R-hat values were under 1.01, indicating good convergence.

Posterior results showed a clear spread in informant competence, with the highest around 0.92 and the lowest near 0.62. The consensus key, derived by rounding the posterior means of $Z_j$, mostly matched the simple majority vote, but differed on a few questions where high-competence informants overruled the majority. This highlights how the CCT model accounts for uneven knowledge across informants—giving more weight to accurate responders. To save time, I used shorter chains but included comments explaining how to scale up the analysis. The model captured both individual differences and group-level agreement in a principled.
